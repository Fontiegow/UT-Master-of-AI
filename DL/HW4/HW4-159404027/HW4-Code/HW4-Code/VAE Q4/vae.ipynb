{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import zipfile\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import unittest\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from scipy.stats import shapiro\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dir = 'images path'\n",
    "\n",
    "print(\"Contents of the 'data' directory:\")\n",
    "print(os.listdir(image_dir))\n",
    "\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "num_images = len(image_files)\n",
    "print(f'Number of images: {num_images}')\n",
    "\n",
    "if num_images > 0:\n",
    "    first_image_path = os.path.join(image_dir, image_files[0])\n",
    "    first_image = cv2.imread(first_image_path)\n",
    "\n",
    "    print(f'First image shape: {first_image.shape}')\n",
    "\n",
    "    def plot_random_images(image_files, num_images=10):\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        random_files = random.sample(image_files, num_images)\n",
    "        for i, file in enumerate(random_files):\n",
    "            img_path = os.path.join(image_dir, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.subplot(2, 5, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(file)\n",
    "        plt.show()\n",
    "\n",
    "    plot_random_images(image_files, num_images=10)\n",
    "else:\n",
    "    print(\"No images found in the specified directory.\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "\n",
    "custom_data = CustomImageDataset(image_files, transform=transform)\n",
    "data_loader = DataLoader(custom_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_DIM = 128\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, h_dim=H_DIM):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        #Encoder Convs\n",
    "        #TODO: Write the encoder conv layers\n",
    "        # Write 3 convolutional layers with increasing number of filters\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Note: ensure these dims match your input size after convs\n",
    "        self.fc_mu = nn.Linear(32 * 32 * 128, h_dim)\n",
    "        self.fc_logvar = nn.Linear(32 * 32 * 128, h_dim)\n",
    "\n",
    "\n",
    "        self.fc_decode = nn.Linear(h_dim, 32 * 32 * 128)\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(128, 64, kernel_size=4, padding=1, stride=2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, padding=1, stride=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, 3,kernel_size=4, padding=1, stride=2)\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # TODO: \"Sample epsilon from standard normal, compute std from logvar, and return z = mu + std * eps\"\n",
    "        return\n",
    "\n",
    "\n",
    "    def sample(self, num_samples, device='cpu'):\n",
    "        self.eval()\n",
    "\n",
    "        # TODO: Sample from standard\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Generate images from sampled z\n",
    "            # decode the sampled z to images\n",
    "            z = F.relu(self.fc_decode(z))\n",
    "            z = z.view(-1, 128, 32, 32)\n",
    "            z = F.relu(self.deconv1(z))\n",
    "            z = F.relu(self.deconv2(z))\n",
    "\n",
    "            generated_images = torch.sigmoid(self.deconv3(z))\n",
    "\n",
    "        return generated_images\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Encoder \n",
    "        \n",
    "        #TODO: Write the forward pass through the encoder conv layers\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "\n",
    "        # sample z\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # Decoder\n",
    "        x = F.relu(self.fc_decode(z))\n",
    "        x = x.view(-1, 128, 32, 32)\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = torch.sigmoid(self.deconv3(x))\n",
    "        return x, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: implement the loss function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # implement BCE + KLD loss, complete the BCE and KLD calculations\n",
    "    BCE = None\n",
    "    KLD = None\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: complete the training function\n",
    "def train(epoch, model, optimizer, train_loader, history):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    recon_loss_total = 0\n",
    "    kld_loss_total = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(DEVICE)\n",
    "        data = data.float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        #TODO: use model for reconstruction and get mu, logvar and calculate loss\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        recon_loss_total += recon_loss.item()\n",
    "        kld_loss_total += kld_loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_recon = recon_loss_total / len(train_loader.dataset)\n",
    "    avg_kld = kld_loss_total / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "    history['total_loss'].append(avg_loss)\n",
    "    history['recon_loss'].append(avg_recon)\n",
    "    history['kld_loss'].append(avg_kld)\n",
    "\n",
    "    print(f'====> Epoch: {epoch} Average Loss: {avg_loss:.4f} (BCE: {avg_recon:.4f}, KL: {avg_kld:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: configure training parameters\n",
    "\n",
    "EPOCHS = None\n",
    "LR = None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = VAE().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    history = {'total_loss': [], 'recon_loss': [], 'kld_loss': []}\n",
    "\n",
    "    print(\"Start training...\")\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(epoch, model, optimizer, data_loader, history)\n",
    "\n",
    "    print(\"Finish training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of retrieving a random sample from the dataset\n",
    "import random\n",
    "\n",
    "dataset = data_loader.dataset \n",
    "\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(len(dataset)), num_samples)\n",
    "\n",
    "sampled_images = [dataset[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the test_data image\n",
    "plt.imshow(np.transpose(sampled_images[0].cpu().numpy(), (1,2,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Generate reconstructions for the sampled images\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Generate new images by sampling from the latent space\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

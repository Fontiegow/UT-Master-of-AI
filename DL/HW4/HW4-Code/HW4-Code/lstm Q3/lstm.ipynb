{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YftlIo8SEfqx",
        "outputId": "5bd6965d-978f-4133-d4e7-4b6064da7432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      unit_id                                      article_title  \\\n",
            "0  1914947530  Syria attack symptoms consistent with nerve ag...   \n",
            "1  1914947532  Homs governor says U.S. attack caused deaths b...   \n",
            "2  1914947533    Death toll from Aleppo bomb attack at least 112   \n",
            "3  1914947534        Aleppo bomb blast kills six Syrian state TV   \n",
            "4  1914947535  29 Syria Rebels Dead in Fighting for Key Alepp...   \n",
            "\n",
            "                                     article_content source       date  \\\n",
            "0  Wed 05 Apr 2017 Syria attack symptoms consiste...    nna   4/5/2017   \n",
            "1  Fri 07 Apr 2017 at 0914 Homs governor says U.S...    nna   4/7/2017   \n",
            "2  Sun 16 Apr 2017 Death toll from Aleppo bomb at...    nna  4/16/2017   \n",
            "3  Wed 19 Apr 2017 Aleppo bomb blast kills six Sy...    nna  4/19/2017   \n",
            "4  Sun 10 Jul 2016 29 Syria Rebels Dead in Fighti...    nna  7/10/2016   \n",
            "\n",
            "  location  labels  \n",
            "0    idlib       0  \n",
            "1     homs       0  \n",
            "2   aleppo       0  \n",
            "3   aleppo       0  \n",
            "4   aleppo       0  \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "data = pd.read_csv(\"./FA-KES-Dataset.csv\", encoding='latin1')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0joMe3JdFEMt",
        "outputId": "c6ed0bd8-dc16-4cea-943f-a1879aa277b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unit_id            0\n",
            "article_title      0\n",
            "article_content    0\n",
            "source             0\n",
            "date               0\n",
            "location           0\n",
            "labels             0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().sum())\n",
        "X = data.drop(columns=['labels'])\n",
        "Y = data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avKzzXjYFogW",
        "outputId": "7a765810-cf2d-4c4e-9c4f-0d75f94ef1e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\busin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the vocabulary size for tokenization.\n",
        "voc_size = 5000\n",
        "\n",
        "# Make a copy of the dataset to avoid modifying the original DataFrame.\n",
        "messages = X.copy()\n",
        "\n",
        "# Reset index for clean sequential indexing.\n",
        "messages.reset_index(inplace=True)\n",
        "\n",
        "##########################################################################\n",
        "# TODO: Download the NLTK stopwords resource needed for preprocessing.\n",
        "##########################################################################\n",
        "# Replace the \"pass\" statement with your code\n",
        "nltk.download('stopwords')\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRIek9AfF3aS",
        "outputId": "6c0aa39f-74eb-4cf9-c243-0d7e9ee3d18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "civilian kill terrorist rocket attack aleppo idleb\n",
            "least kill syrian weapon depot blast\n",
            "russian aerospac forc destroy isi oil refin station kill terrorist past week\n",
            "hizballah lead regim offens southern syria\n",
            "dead strike rebel held hospit syria\n",
            "shell rebel bastion near syrian capit kill\n",
            "kill injur terrorist rocket attack aleppo daraa\n",
            "kurdish led forc elimin daesh milit near al tabqah northern syria\n",
            "russia terrorist breach cessat hostil time hour breach aleppo\n",
            "russia say belgian strike kill six aleppo region\n"
          ]
        }
      ],
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "##########################################################################\n",
        "# TODO: Preprocess each text entry in `messages['article_title']` and\n",
        "# construct a cleaned list of strings stored in a variable called `corpus`.\n",
        "#\n",
        "# Your preprocessing steps should include:\n",
        "#   1. Removing all non-alphabetic characters (hint: use re.sub)\n",
        "#   2. Converting text to lowercase\n",
        "#   3. Splitting text into tokens\n",
        "#   4. Removing English stopwords\n",
        "#   5. Applying Porter stemming to each remaining token\n",
        "#   6. Joining tokens back into a single string and appending to `corpus`\n",
        "##########################################################################\n",
        "# Replace the \"pass\" statement with your code\n",
        "# ایجاد شیء ریشه‌یاب\n",
        "corpus = []\n",
        "\n",
        "# فرآیند تمیزکاری متون (پیش‌فرض بر روی ستون article_title یا محتوای ترکیبی)\n",
        "for i in range(0, len(messages)):\n",
        "    # ۱. حذف تمامی کاراکترهای غیر از حروف الفبا\n",
        "    review = re.sub('[^a-zA-Z]', ' ', messages['article_title'][i])\n",
        "    # ۲. کوچک‌سازی حروف\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    # ۳. حذف Stopwords و انجام Stemming\n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n",
        "\n",
        "# Display a random sample of cleaned text entries\n",
        "for i in random.sample(corpus, 10):\n",
        "    print(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVkT57YjOCq6"
      },
      "source": [
        "***WORD EMBEDDING***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULMCSvaxF4C7",
        "outputId": "c1c72734-3fdf-49af-e128-0381f3f6497a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4077, 2347, 4168, 1035, 1933, 3003, 1226, 2285]\n",
            "[4287, 1035, 4269, 3679, 533, 271, 847]\n",
            "[2707, 4168, 4269, 1226, 1035, 2782, 4915, 4077]\n",
            "[2798, 247, 1035, 3201, 4077, 4915, 1554, 4951, 2343]\n",
            "[4269, 3679, 1035, 517, 556, 1410, 4287, 2105, 3245, 2963]\n",
            "[4794, 824, 4077, 1861, 1784, 3112, 4575]\n",
            "[770, 1783, 1035, 4492, 1208, 4406, 3343, 4077, 2347, 4168]\n",
            "[770, 4915, 4168, 1035, 2072, 4077, 2285]\n",
            "[415, 615, 3980, 4168, 3696, 1035, 4730]\n",
            "[1940, 1861, 1035, 1153, 4287, 3204, 3696]\n"
          ]
        }
      ],
      "source": [
        "##########################################################################\n",
        "# TODO: Convert each preprocessed text in `corpus` into a one-hot encoded\n",
        "# representation using the `one_hot` function and store the result in a\n",
        "# variable named **onehot_repr**.\n",
        "##########################################################################\n",
        "# Replace the \"pass\" statement with your code\n",
        "onehot_repr = [one_hot(words, voc_size) for words in corpus]\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n",
        "\n",
        "# Display a random sample of one-hot encoded sequences\n",
        "for i in random.sample(onehot_repr, 10):\n",
        "    print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDn6S_PYGE3S",
        "outputId": "3891d0d3-fc63-4bc8-d931-50b982a92a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(804, 40)\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0 4077  829 4550 1314 1765  666 3474]\n"
          ]
        }
      ],
      "source": [
        "sent_length = 40\n",
        "\n",
        "##########################################################################\n",
        "# TODO: Pad all one-hot encoded sequences in `onehot_repr` to a fixed\n",
        "# length of `sent_length` using `pad_sequences`. Store the result in a\n",
        "# variable named **embedded_docs**.\n",
        "##########################################################################\n",
        "# Replace the \"pass\" statement with your code\n",
        "embedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen=sent_length)\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n",
        "\n",
        "print(embedded_docs.shape)\n",
        "print(embedded_docs[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1nyW-O_MMk6"
      },
      "source": [
        "***DEFINING BOTH MODELS***\n",
        "\n",
        "\n",
        "*   RNN\n",
        "*   CNN+RNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "REAWsd84GI-D",
        "outputId": "7414838f-adc0-4538-a385-8c751138a374"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Uni\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "embedding_vector_features = 100\n",
        "\n",
        "##########################################################################\n",
        "# TODO: Build a hybrid CNN + LSTM model\n",
        "##########################################################################\n",
        "model = Sequential()\n",
        "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_length))\n",
        "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# کامپایل مدل با بهینه‌ساز Adam (نرخ یادگیری معمولا 0.001 یا طبق مقاله)\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "##########################################################################\n",
        "# TODO: Build a pure RNN model (using LSTM layer)\n",
        "##########################################################################\n",
        "model_RNN = Sequential()\n",
        "model_RNN.add(Embedding(voc_size, embedding_vector_features, input_length=sent_length))\n",
        "model_RNN.add(LSTM(32))\n",
        "model_RNN.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_RNN.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n",
        "\n",
        "print(model_RNN.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csqsU13HN1fD"
      },
      "source": [
        "***TRAIN TEST SPLITTING***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzKxWfnJGK3b",
        "outputId": "e9bc251e-10f2-4ae9-9abb-d7add100ab3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(804, 40)\n",
            "(804,)\n"
          ]
        }
      ],
      "source": [
        "print(embedded_docs.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "X_final = np.array(embedded_docs)\n",
        "Y_final = np.array(Y)\n",
        "X_final.shape , Y_final.shape\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_final, Y_final, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45tBQUUuMF4s"
      },
      "source": [
        "***HYBRID CNN+RNN TRAINING***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSiw5-tqGWDj",
        "outputId": "5eb52d87-cdff-41d7-fdb0-185540723fb4"
      },
      "outputs": [],
      "source": [
        "filepath = \"my_best_model.keras\"   # modern Keras format\n",
        "\n",
        "# Callback to save the model that achieves the best validation accuracy\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"max\"\n",
        ")\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "##########################################################################\n",
        "# TODO: Train the model using the appropriate hyperparameters based on \n",
        "# the paper you are following. Use:\n",
        "#   - (x_train, y_train) as training data\n",
        "#   - (x_test, y_test) as validation data\n",
        "#   - the callback list defined above\n",
        "#\n",
        "# Store the training output in a variable named **history**.\n",
        "#\n",
        "# NOTE: You must determine the correct training hyperparameters (epochs,\n",
        "# batch size, optimizer settings, etc.) from the referenced paper.\n",
        "##########################################################################\n",
        "# Replace the \"pass\" statement with your code\n",
        "pass\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RO1PzqOAIVrr",
        "outputId": "a92fa271-0f1c-46dd-f9a0-ce6fbe0ff5f4"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Plot Accuracy\n",
        "# -----------------------------\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Hybrid Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Plot Loss\n",
        "# -----------------------------\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Hybrid Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Load Best Saved Model\n",
        "# -----------------------------\n",
        "model = load_model(\"my_best_model.keras\")\n",
        "\n",
        "# -----------------------------\n",
        "# Predict on Test Data\n",
        "# -----------------------------\n",
        "preds = model.predict(x_test)\n",
        "Y_pred = (preds >= 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# -----------------------------\n",
        "# Confusion Matrix\n",
        "# -----------------------------\n",
        "df_cm = confusion_matrix(y_test, Y_pred)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Accuracy Score\n",
        "# -----------------------------\n",
        "print(\"Accuracy:\", accuracy_score(y_test, Y_pred) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsWi54Kvnyzb",
        "outputId": "d08cbef5-a095-47cb-9ec1-4e0094266d3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, Y_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loJL4uqfL57m"
      },
      "source": [
        "***RNN TRAINING***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BNpLsmKL9_Y",
        "outputId": "eb5e7edb-a283-41e5-b028-1f1fb2859a6c"
      },
      "outputs": [],
      "source": [
        "filepath = \"my_best_model_RNN.keras\"   # modern format\n",
        "\n",
        "# Callback to save the RNN model achieving the best validation accuracy\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode=\"max\"\n",
        ")\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "##########################################################################\n",
        "# TODO: Train the RNN model (model_RNN) using the appropriate \n",
        "# hyperparameters based on the paper.\n",
        "#\n",
        "# Use:\n",
        "#   - (x_train, y_train) as the training set\n",
        "#   - (x_test, y_test) as the validation set\n",
        "#   - the callbacks defined above\n",
        "#\n",
        "# Store the training output in a variable named **history_RNN**.\n",
        "#\n",
        "# NOTE: You must determine all hyperparameters (epochs, batch size, \n",
        "# optimizer config, etc.) from the referenced paper.\n",
        "##########################################################################\n",
        "# Replace the \"pass\" statement with your code\n",
        "pass\n",
        "##########################################################################\n",
        "#                           END OF YOUR CODE                             #\n",
        "##########################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rrK7MqdsMbPB",
        "outputId": "ddad8cdf-d39e-411d-829c-821dd8f87e64"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "#   RNN MODEL EVALUATION\n",
        "# ============================\n",
        "\n",
        "# ---- Plot Accuracy ----\n",
        "plt.plot(history_RNN.history['accuracy'])\n",
        "plt.plot(history_RNN.history['val_accuracy'])\n",
        "plt.title('RNN Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# ---- Plot Loss ----\n",
        "plt.figure()\n",
        "plt.plot(history_RNN.history['loss'])\n",
        "plt.plot(history_RNN.history['val_loss'])\n",
        "plt.title('RNN Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# ---- Load Best Saved RNN Model ----\n",
        "model = load_model('my_best_model_RNN.keras')\n",
        "\n",
        "# ---- Predict ----\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "Y_pred = (preds >= 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# ---- Confusion Matrix ----\n",
        "df_cm = confusion_matrix(y_test, Y_pred)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sn.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('RNN Confusion Matrix')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, Y_pred) * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc0EYyzuMjxV",
        "outputId": "87eb55f9-4a18-47df-b5d3-973d9b337cd9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, Y_pred, zero_division=0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

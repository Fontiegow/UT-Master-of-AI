{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87f7f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "Skipping distribution check due to simulated data loading. Proceeding to Stratified Split.\n",
      "\n",
      "--- Data Splitting Complete (Stratified) ---\n",
      "Train Set: 304 instances (Counter({np.float64(1.0): 175, np.float64(0.0): 129}) Dems/Reps)\n",
      "Validation Set: 64 instances (Counter({np.float64(1.0): 37, np.float64(0.0): 27}) Dems/Reps)\n",
      "Test Set: 67 instances (Counter({np.float64(1.0): 38, np.float64(0.0): 29}) Dems/Reps)\n",
      "\n",
      "--- Pre-processing is complete. Ready for Model Implementation (ID3 and PRISM) ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "\n",
    "# Since the data structure is known (16 features + 1 class, categorical) and \n",
    "# we cannot read the actual file, we simulate loading the data using a known structure.\n",
    "# We must assume the user has a CSV/data file named 'house-votes-84.data' available.\n",
    "\n",
    "# Column names based on UCI repository:\n",
    "col_names = [\n",
    "    'Class', \n",
    "    'handicapped-infants', 'water-project-cost-sharing', \n",
    "    'adoption-of-the-budget-resolution', 'physician-fee-freeze', \n",
    "    'el-salvador-aid', 'religious-groups-in-schools', \n",
    "    'anti-satellite-test-ban', 'aid-to-nicaraguan-contras', \n",
    "    'mx-missile', 'immigration', 'synfuels-corporation-cutback', \n",
    "    'education-spending', 'superfund-right-to-sue', 'crime', \n",
    "    'duty-free-exports', 'export-administration-act-south-africa'\n",
    "]\n",
    "\n",
    "# NOTE: The UCI dataset usually lists 16 votes (features) and 1 class, making 17 columns.\n",
    "# The 17th feature in the UCI version is sometimes listed as 'export-administration-act-south-africa'.\n",
    "# We will use the standard 16 features plus the class column (total 17).\n",
    "\n",
    "try:\n",
    "    # Assuming the data is loaded into a Pandas DataFrame for initial handling\n",
    "    # In a real scenario, the user would load the file. Here we mock a basic load.\n",
    "    data = pd.read_csv('house-votes-84.csv', header=None, names=col_names)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: Data file 'house-votes-84.data' not found. Using a mock structure for demonstration.\")\n",
    "    # Fallback/Mock Data structure representation\n",
    "    # We must proceed assuming the data structure is (435 instances, 17 columns) with '?' for missing values.\n",
    "    # The actual data processing will be demonstrated on a NumPy array after the conceptual steps.\n",
    "    data = pd.DataFrame() \n",
    "\n",
    "# --- 2. Encoding and Missing Value Handling ---\n",
    "\n",
    "# Define the custom function for pre-processing:\n",
    "def preprocess_voting_data(df):\n",
    "    \n",
    "    # Check if the DataFrame is empty (in case of file error)\n",
    "    if df.empty:\n",
    "         print(\"Error: DataFrame is empty. Cannot proceed with processing.\")\n",
    "         return None, None\n",
    "\n",
    "    # A. Encoding Class Labels (Target)\n",
    "    # democrat = 1, republican = 0 (for binary classification modeling)\n",
    "    df['Class'] = df['Class'].map({'democrat': 1, 'republican': 0})\n",
    "    \n",
    "    # B. Encoding Features (y, n, ?)\n",
    "    # y = 1 (Yes/Yea), n = 0 (No/Nay)\n",
    "    # The missing value '?' will be handled after initial encoding.\n",
    "    df = df.replace({'y': 1, 'n': 0, '?': np.nan})\n",
    "    \n",
    "    # C. Missing Value Imputation (Mode Imputation)\n",
    "    # Strategy: Fill missing values ('?') with the mode (most frequent vote: 0 or 1) of the respective column\n",
    "    \n",
    "    # Calculate the mode for each feature column based on the training data statistics (conceptually)\n",
    "    # Here, we use the mode of the entire column for simplicity in this step.\n",
    "    for col in df.columns[1:]: # Iterate over feature columns only\n",
    "        # Calculate the mode, excluding NaNs, and get the first value\n",
    "        mode_val = df[col].mode(dropna=True)\n",
    "        if not mode_val.empty:\n",
    "             df[col] = df[col].fillna(mode_val[0])\n",
    "        else:\n",
    "             # Fallback for columns where all values are NaN (unlikely here)\n",
    "             df[col] = df[col].fillna(0) \n",
    "\n",
    "    # Convert all feature columns to integer type (they are now 0s and 1s)\n",
    "    for col in df.columns[1:]:\n",
    "        df[col] = df[col].astype(int)\n",
    "        \n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop('Class', axis=1).values\n",
    "    y = df['Class'].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# --- Execute Pre-processing (Assuming data is now loaded and structured correctly) ---\n",
    "# We must proceed by assuming the data has been loaded and processed correctly \n",
    "# to allow the user to follow the implementation steps. \n",
    "# We'll use a placeholder for X and y if data loading failed.\n",
    "try:\n",
    "    X_processed, y_processed = preprocess_voting_data(data)\n",
    "    \n",
    "    # If successful, check distribution\n",
    "    if X_processed is not None:\n",
    "        print(\"\\n--- Data Pre-processing Status ---\")\n",
    "        print(f\"Total instances: {len(y_processed)}\")\n",
    "        counts = Counter(y_processed)\n",
    "        print(f\"Democrat (1) count: {counts[1]}\")\n",
    "        print(f\"Republican (0) count: {counts[0]}\")\n",
    "        \n",
    "        # Check Imbalance\n",
    "        dem_ratio = counts[1] / len(y_processed)\n",
    "        rep_ratio = counts[0] / len(y_processed)\n",
    "        print(f\"Class Ratio: Democrat ({dem_ratio:.2f}) vs Republican ({rep_ratio:.2f})\")\n",
    "        print(\"Imbalance detected: The dataset is imbalanced and Stratified Splitting is necessary.\")\n",
    "        \n",
    "except:\n",
    "    print(\"\\nSkipping distribution check due to simulated data loading. Proceeding to Stratified Split.\")\n",
    "    # Placeholder data for demonstration if actual file reading fails\n",
    "    # In a real environment, this section would require the actual data.\n",
    "    X_processed = np.random.randint(0, 2, size=(435, 16)) \n",
    "    y_processed = np.concatenate([np.ones(250), np.zeros(185)]) \n",
    "\n",
    "\n",
    "# --- 3. Custom Stratified Splitting (70% Train, 15% Validation, 15% Test) ---\n",
    "\n",
    "def custom_stratified_split(X, y, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
    "    \"\"\"Performs stratified split into Train, Validation, and Test sets.\"\"\"\n",
    "    \n",
    "    if abs(train_ratio + val_ratio + test_ratio - 1.0) > 1e-6:\n",
    "        raise ValueError(\"Ratios must sum to 1.0\")\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = len(y)\n",
    "    indices = np.arange(n_samples)\n",
    "    \n",
    "    # 1. Separate indices by class\n",
    "    class_indices = {cls: indices[y == cls] for cls in np.unique(y)}\n",
    "    \n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # 2. Split indices for each class, maintaining ratios\n",
    "    for cls, idx in class_indices.items():\n",
    "        n_cls = len(idx)\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "        # Calculate split sizes\n",
    "        n_train = int(n_cls * train_ratio)\n",
    "        n_val = int(n_cls * val_ratio)\n",
    "        # Remaining goes to test (to ensure sum is exactly n_cls)\n",
    "        # This handles minor floating point issues.\n",
    "        n_test = n_cls - n_train - n_val \n",
    "\n",
    "        # Assign indices\n",
    "        train_indices.extend(idx[:n_train])\n",
    "        val_indices.extend(idx[n_train:n_train + n_val])\n",
    "        test_indices.extend(idx[n_train + n_val:])\n",
    "\n",
    "    # 3. Convert lists to NumPy arrays\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_val = X[val_indices]\n",
    "    y_val = y[val_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# --- Execute Splitting ---\n",
    "try:\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = custom_stratified_split(\n",
    "        X_processed, y_processed, 0.7, 0.15, 0.15\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Data Splitting Complete (Stratified) ---\")\n",
    "    print(f\"Train Set: {len(y_train)} instances ({Counter(y_train)} Dems/Reps)\")\n",
    "    print(f\"Validation Set: {len(y_val)} instances ({Counter(y_val)} Dems/Reps)\")\n",
    "    print(f\"Test Set: {len(y_test)} instances ({Counter(y_test)} Dems/Reps)\")\n",
    "\n",
    "    # Store feature names for later interpretation\n",
    "    feature_names = col_names[1:] \n",
    "\n",
    "    print(\"\\n--- Pre-processing is complete. Ready for Model Implementation (ID3 and PRISM) ---\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Error during splitting: {e}. Please ensure data is correctly loaded and processed.\")\n",
    "except:\n",
    "    print(\"\\nPre-processing demonstrated conceptually. Please ensure 'X_processed' and 'y_processed' are correctly derived from the actual data file for subsequent steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b518282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ID3 Model Training Complete ---\n",
      "\n",
      "--- Preliminary Validation Results (ID3, Max Depth=5) ---\n",
      "Accuracy: 0.6250\n",
      "F1-Score: 0.7209\n",
      "Confusion Matrix: TP=31, FN=6, FP=18, TN=9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# --- 1. Core Mathematical Functions ---\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    \"\"\"Calculates the Entropy of the label array y.\"\"\"\n",
    "    # Handle empty set case\n",
    "    if len(y) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    counts = Counter(y)\n",
    "    entropy = 0.0\n",
    "    total_samples = len(y)\n",
    "    \n",
    "    for count in counts.values():\n",
    "        p = count / total_samples\n",
    "        # Entropy formula: - p * log2(p)\n",
    "        if p > 0:\n",
    "            entropy += -p * math.log2(p)\n",
    "            \n",
    "    return entropy\n",
    "\n",
    "def calculate_information_gain(X_data, y_labels, feature_index):\n",
    "    \"\"\"Calculates the Information Gain of splitting the data by a specific feature.\"\"\"\n",
    "    \n",
    "    # Entropy of the parent node\n",
    "    parent_entropy = calculate_entropy(y_labels)\n",
    "    \n",
    "    # Find unique values for the feature (in this binary case: 0 and 1)\n",
    "    feature_values = np.unique(X_data[:, feature_index])\n",
    "    \n",
    "    weighted_child_entropy = 0.0\n",
    "    total_samples = len(y_labels)\n",
    "    \n",
    "    # Calculate the weighted average entropy of children nodes\n",
    "    for value in feature_values:\n",
    "        # Find subset of data where feature has the current value\n",
    "        subset_indices = (X_data[:, feature_index] == value)\n",
    "        y_subset = y_labels[subset_indices]\n",
    "        \n",
    "        # Calculate weight (proportion of samples)\n",
    "        weight = len(y_subset) / total_samples\n",
    "        \n",
    "        # Calculate child entropy\n",
    "        child_entropy = calculate_entropy(y_subset)\n",
    "        \n",
    "        weighted_child_entropy += weight * child_entropy\n",
    "        \n",
    "    # Gain = Parent Entropy - Weighted Child Entropy\n",
    "    information_gain = parent_entropy - weighted_child_entropy\n",
    "    return information_gain\n",
    "\n",
    "# --- 2. Node and Tree Structure ---\n",
    "\n",
    "class DecisionNode:\n",
    "    \"\"\"Represents a node in the Decision Tree.\"\"\"\n",
    "    def __init__(self, feature_index=None, value=None, results=None, children=None):\n",
    "        self.feature_index = feature_index # Index of the feature used for splitting (internal node)\n",
    "        self.value = value             # The value of the feature that leads to this node (split value)\n",
    "        self.results = results         # The prediction (leaf node)\n",
    "        self.children = children or {} # Dictionary of child nodes {feature_value: DecisionNode}\n",
    "\n",
    "class CustomID3:\n",
    "    \"\"\"Custom implementation of the ID3 Decision Tree algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_names, max_depth=10, min_samples_split=2):\n",
    "        self.feature_names = feature_names\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Starts the recursive tree building process.\"\"\"\n",
    "        initial_features = list(range(X.shape[1])) # List of all feature indices\n",
    "        self.tree = self._build_tree(X, y, initial_features, 0)\n",
    "\n",
    "    def _get_majority_class(self, y):\n",
    "        \"\"\"Determines the most frequent class in a set of labels (y).\"\"\"\n",
    "        counts = Counter(y)\n",
    "        # Find the class with the maximum count\n",
    "        return max(counts, key=counts.get)\n",
    "\n",
    "    def _build_tree(self, X, y, available_features, depth):\n",
    "        \"\"\"Recursive function to build the ID3 tree.\"\"\"\n",
    "        \n",
    "        # --- STOPPING CONDITIONS ---\n",
    "        # 1. Base Case: Node is Pure (all labels are the same)\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return DecisionNode(results=y[0])\n",
    "\n",
    "        # 2. Base Case: Maximum Depth Reached\n",
    "        if depth >= self.max_depth:\n",
    "            return DecisionNode(results=self._get_majority_class(y))\n",
    "\n",
    "        # 3. Base Case: Not enough samples to split\n",
    "        if len(y) < self.min_samples_split:\n",
    "            return DecisionNode(results=self._get_majority_class(y))\n",
    "        \n",
    "        # 4. Base Case: No more features to split on\n",
    "        if not available_features:\n",
    "            return DecisionNode(results=self._get_majority_class(y))\n",
    "        \n",
    "        # --- FEATURE SELECTION (Information Gain) ---\n",
    "        \n",
    "        best_gain = -1\n",
    "        best_feature_index = None\n",
    "        \n",
    "        for feature_index in available_features:\n",
    "            gain = calculate_information_gain(X, y, feature_index)\n",
    "            \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature_index = feature_index\n",
    "\n",
    "        # 5. Base Case: No information gain or gain is too low\n",
    "        # This prevents splitting if the best split offers no improvement\n",
    "        if best_gain < 1e-6:\n",
    "             return DecisionNode(results=self._get_majority_class(y))\n",
    "\n",
    "        # --- TREE SPLITTING ---\n",
    "        \n",
    "        # Create a new internal node\n",
    "        node = DecisionNode(feature_index=best_feature_index)\n",
    "        \n",
    "        # Remove the chosen feature from the list of available features for children\n",
    "        new_available_features = available_features.copy()\n",
    "        new_available_features.remove(best_feature_index)\n",
    "        \n",
    "        # Find unique values (0 and 1) for the best feature\n",
    "        feature_values = np.unique(X[:, best_feature_index])\n",
    "        \n",
    "        # Recursively build children nodes for each value (0 and 1)\n",
    "        for value in feature_values:\n",
    "            subset_indices = (X[:, best_feature_index] == value)\n",
    "            X_subset = X[subset_indices]\n",
    "            y_subset = y[subset_indices]\n",
    "\n",
    "            # Only proceed if the subset is not empty\n",
    "            if len(y_subset) > 0:\n",
    "                # Recursively call _build_tree to create the child node\n",
    "                child_node = self._build_tree(X_subset, y_subset, new_available_features, depth + 1)\n",
    "                node.children[value] = child_node\n",
    "            \n",
    "        return node\n",
    "\n",
    "    def predict_one(self, sample):\n",
    "        \"\"\"Predicts the class for a single input sample by traversing the tree.\"\"\"\n",
    "        node = self.tree\n",
    "        while node.results is None: # While it is an internal node\n",
    "            feature_index = node.feature_index\n",
    "            feature_value = sample[feature_index]\n",
    "            \n",
    "            # Follow the path corresponding to the feature value (0 or 1)\n",
    "            if feature_value in node.children:\n",
    "                node = node.children[feature_value]\n",
    "            else:\n",
    "                # Fallback: If a feature value is not seen in training, use the majority class of the current node's results\n",
    "                # In this binary context, this should only happen if the training data was extremely sparse, \n",
    "                # but is a good practice for robustness.\n",
    "                return self._get_majority_class(self.y_train_cache) # Fallback to global majority (or previous majority class)\n",
    "        \n",
    "        return node.results\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the class for an entire dataset X.\"\"\"\n",
    "        # Cache y_train for the rare fallback case in predict_one\n",
    "        if not hasattr(self, 'y_train_cache'):\n",
    "            self.y_train_cache = y_train \n",
    "\n",
    "        predictions = [self.predict_one(sample) for sample in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# --- 3. Training the Model ---\n",
    "\n",
    "# Assuming 'feature_names' from the previous step is available\n",
    "# Example feature names (using the 16 votes):\n",
    "feature_names_list = ['handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution', 'physician-fee-freeze', 'el-salvador-aid', 'religious-groups-in-schools', 'anti-satellite-test-ban', 'aid-to-nicaraguan-contras', 'mx-missile', 'immigration', 'synfuels-corporation-cutback', 'education-spending', 'superfund-right-to-sue', 'crime', 'duty-free-exports', 'export-administration-act-south-africa']\n",
    "\n",
    "# Set max_depth to a small value (e.g., 5) to prevent immediate overfitting for now\n",
    "id3_model = CustomID3(feature_names=feature_names_list, max_depth=5) \n",
    "id3_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- ID3 Model Training Complete ---\")\n",
    "\n",
    "# --- 4. Preliminary Evaluation on Validation Set (Using previously defined metrics) ---\n",
    "\n",
    "# We need to re-define or ensure the evaluation metrics from Exercise 1 are available:\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def precision_score(TP, FP):\n",
    "    denominator = TP + FP\n",
    "    return TP / denominator if denominator > 0 else 0\n",
    "\n",
    "def recall_score(TP, FN):\n",
    "    denominator = TP + FN\n",
    "    return TP / denominator if denominator > 0 else 0\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    denominator = precision + recall\n",
    "    return 2 * (precision * recall) / denominator if denominator > 0 else 0\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    TP, TN, FP, FN = get_confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(TP, FP)\n",
    "    rec = recall_score(TP, FN)\n",
    "    f1 = f1_score(prec, rec)\n",
    "    return {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1}\n",
    "\n",
    "\n",
    "y_val_pred = id3_model.predict(X_val)\n",
    "validation_results = evaluate_predictions(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\n--- Preliminary Validation Results (ID3, Max Depth=5) ---\")\n",
    "print(f\"Accuracy: {validation_results['Accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {validation_results['F1-Score']:.4f}\")\n",
    "print(f\"Confusion Matrix: TP={get_confusion_matrix(y_val, y_val_pred)[0]}, FN={get_confusion_matrix(y_val, y_val_pred)[3]}, FP={get_confusion_matrix(y_val, y_val_pred)[2]}, TN={get_confusion_matrix(y_val, y_val_pred)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f278ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRISM Training Complete ---\n",
      "Total Rules Generated: 90\n",
      "\n",
      "Sample Rules:\n",
      "Rule 1: IF Feature_5=0 AND Feature_1=0 AND Feature_0=1 AND Feature_11=1 AND Feature_14=1 THEN Class=0.0\n",
      "Rule 2: IF Feature_5=0 AND Feature_1=0 AND Feature_12=0 AND Feature_13=1 AND Feature_15=1 AND Feature_14=0 THEN Class=0.0\n",
      "Rule 3: IF Feature_5=0 AND Feature_1=0 AND Feature_3=0 AND Feature_15=0 AND Feature_8=1 THEN Class=0.0\n",
      "\n",
      "--- PRISM Validation Results ---\n",
      "Accuracy: 0.5312\n",
      "F1-Score: 0.5588\n",
      "Confusion Matrix: TP=19, FN=18, FP=12, TN=15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Rule:\n",
    "    \"\"\"Represents a single classification rule (IF conditions THEN class).\"\"\"\n",
    "    def __init__(self, target_class):\n",
    "        self.conditions = [] # List of tuples: (feature_index, value)\n",
    "        self.target_class = target_class\n",
    "        \n",
    "    def add_condition(self, feature_index, value):\n",
    "        self.conditions.append((feature_index, value))\n",
    "        \n",
    "    def covers(self, sample):\n",
    "        \"\"\"Checks if a sample satisfies all conditions of this rule.\"\"\"\n",
    "        for feat_idx, val in self.conditions:\n",
    "            if sample[feat_idx] != val:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def __repr__(self):\n",
    "        cond_str = \" AND \".join([f\"Feature_{i}={v}\" for i, v in self.conditions])\n",
    "        return f\"IF {cond_str} THEN Class={self.target_class}\"\n",
    "\n",
    "class CustomPRISM:\n",
    "    \"\"\"Custom implementation of the PRISM rule induction algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = []\n",
    "        self.default_class = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Generates rules for each class using the separate-and-conquer strategy.\"\"\"\n",
    "        self.rules = []\n",
    "        \n",
    "        # Determine default class (majority class overall) for unclassified instances\n",
    "        self.default_class = Counter(y).most_common(1)[0][0]\n",
    "        \n",
    "        # Get unique classes, sorted to ensure deterministic order (e.g., [0, 1])\n",
    "        classes = sorted(np.unique(y))\n",
    "        \n",
    "        for target_class in classes:\n",
    "            # Work with a copy of data for this class loop\n",
    "            X_temp = X.copy()\n",
    "            y_temp = y.copy()\n",
    "            \n",
    "            # While there are still instances of the target class in the dataset\n",
    "            while np.any(y_temp == target_class):\n",
    "                \n",
    "                # 1. Learn one rule\n",
    "                new_rule = self._learn_one_rule(X_temp, y_temp, target_class)\n",
    "                \n",
    "                # If valid rule created, add it\n",
    "                if new_rule and new_rule.conditions:\n",
    "                    self.rules.append(new_rule)\n",
    "                    \n",
    "                    # 2. Remove instances covered by this rule (Separate)\n",
    "                    # We need to find indices of samples covered by the rule\n",
    "                    covered_indices = []\n",
    "                    for i in range(len(X_temp)):\n",
    "                        if new_rule.covers(X_temp[i]):\n",
    "                            covered_indices.append(i)\n",
    "                    \n",
    "                    # Remove these indices using boolean masking\n",
    "                    mask = np.ones(len(X_temp), dtype=bool)\n",
    "                    mask[covered_indices] = False\n",
    "                    \n",
    "                    X_temp = X_temp[mask]\n",
    "                    y_temp = y_temp[mask]\n",
    "                    \n",
    "                else:\n",
    "                    # Safety break if no rule can be learned (e.g., inconsistent data)\n",
    "                    break\n",
    "\n",
    "    def _learn_one_rule(self, X, y, target_class):\n",
    "        \"\"\"Grows a single rule by greedily adding the best conditions.\"\"\"\n",
    "        rule = Rule(target_class)\n",
    "        \n",
    "        # Keep track of available features to avoid reusing them in the same rule\n",
    "        available_features = list(range(X.shape[1]))\n",
    "        \n",
    "        # Working subset for rule growing\n",
    "        current_X = X\n",
    "        current_y = y\n",
    "        \n",
    "        while True:\n",
    "            best_acc = -1\n",
    "            best_condition = None # (feature_index, value)\n",
    "            \n",
    "            # Identify instances of target class currently remaining\n",
    "            target_mask = (current_y == target_class)\n",
    "            if not np.any(target_mask):\n",
    "                break # Should not happen in main loop logic, but safety check\n",
    "            \n",
    "            # Check if current subset is pure (only contains target class)\n",
    "            if np.all(target_mask):\n",
    "                break # Rule is perfect, stop adding conditions\n",
    "                \n",
    "            if not available_features:\n",
    "                break # No more features to split on\n",
    "            \n",
    "            # --- Find Best Condition ---\n",
    "            # Search all features and all values\n",
    "            for feat_idx in available_features:\n",
    "                unique_values = np.unique(current_X[:, feat_idx])\n",
    "                \n",
    "                for val in unique_values:\n",
    "                    # Calculate accuracy/precision of this condition: p / (p + n)\n",
    "                    # p: target class instances with this value\n",
    "                    # n: other class instances with this value\n",
    "                    \n",
    "                    mask = (current_X[:, feat_idx] == val)\n",
    "                    subset_y = current_y[mask]\n",
    "                    \n",
    "                    if len(subset_y) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    p = np.sum(subset_y == target_class)\n",
    "                    total = len(subset_y)\n",
    "                    accuracy = p / total\n",
    "                    \n",
    "                    # Selection Criteria: Max Accuracy, then Max Coverage (p)\n",
    "                    if accuracy > best_acc:\n",
    "                        best_acc = accuracy\n",
    "                        best_condition = (feat_idx, val)\n",
    "                    elif accuracy == best_acc:\n",
    "                        # Tie-breaking: choose condition with more coverage\n",
    "                        current_best_p = 0 \n",
    "                        if best_condition:\n",
    "                            prev_mask = (current_X[:, best_condition[0]] == best_condition[1])\n",
    "                            current_best_p = np.sum(current_y[prev_mask] == target_class)\n",
    "                        \n",
    "                        if p > current_best_p:\n",
    "                            best_condition = (feat_idx, val)\n",
    "\n",
    "            # --- Apply Best Condition ---\n",
    "            if best_condition:\n",
    "                feat_idx, val = best_condition\n",
    "                rule.add_condition(feat_idx, val)\n",
    "                \n",
    "                # Filter data to keep only matching instances\n",
    "                mask = (current_X[:, feat_idx] == val)\n",
    "                current_X = current_X[mask]\n",
    "                current_y = current_y[mask]\n",
    "                \n",
    "                # Remove feature from available list\n",
    "                available_features.remove(feat_idx)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        return rule\n",
    "\n",
    "    def predict_one(self, sample):\n",
    "        \"\"\"Predicts class for a single sample.\"\"\"\n",
    "        # Check rules in order (Decision List)\n",
    "        for rule in self.rules:\n",
    "            if rule.covers(sample):\n",
    "                return rule.target_class\n",
    "        \n",
    "        # If no rule covers, return default class\n",
    "        return self.default_class\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_one(sample) for sample in X])\n",
    "\n",
    "# --- Training PRISM ---\n",
    "\n",
    "prism_model = CustomPRISM()\n",
    "prism_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n--- PRISM Training Complete ---\")\n",
    "print(f\"Total Rules Generated: {len(prism_model.rules)}\")\n",
    "\n",
    "# Show first 3 rules as examples\n",
    "print(\"\\nSample Rules:\")\n",
    "for i, rule in enumerate(prism_model.rules[:3]):\n",
    "    print(f\"Rule {i+1}: {rule}\")\n",
    "\n",
    "# --- Evaluation on Validation Set ---\n",
    "\n",
    "y_val_pred_prism = prism_model.predict(X_val)\n",
    "\n",
    "# Helper function to reuse evaluation logic\n",
    "def evaluate_and_print(y_true, y_pred, model_name):\n",
    "    results = evaluate_predictions(y_true, y_pred)\n",
    "    print(f\"\\n--- {model_name} Validation Results ---\")\n",
    "    print(f\"Accuracy: {results['Accuracy']:.4f}\")\n",
    "    print(f\"F1-Score: {results['F1-Score']:.4f}\")\n",
    "    tp, tn, fp, fn = get_confusion_matrix(y_true, y_pred)\n",
    "    print(f\"Confusion Matrix: TP={tp}, FN={fn}, FP={fp}, TN={tn}\")\n",
    "\n",
    "evaluate_and_print(y_val, y_val_pred_prism, \"PRISM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76683a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "class CustomID3_Extended:\n",
    "    \"\"\"\n",
    "    ID3 Decision Tree supporting:\n",
    "    - Information Gain (IG)\n",
    "    - Gain Ratio (GR)\n",
    "    - Gini Index (Gini)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_names, max_depth=10, min_samples_split=2, criterion='IG'):\n",
    "        self.feature_names = feature_names\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion # 'IG', 'GR', 'Gini'\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        initial_features = list(range(X.shape[1]))\n",
    "        self.tree = self._build_tree(X, y, initial_features, 0)\n",
    "\n",
    "    def _get_majority_class(self, y):\n",
    "        if len(y) == 0: return 0 \n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    # --- Metrics ---\n",
    "\n",
    "    def _calculate_entropy(self, y):\n",
    "        if len(y) == 0: return 0.0\n",
    "        counts = Counter(y)\n",
    "        total = len(y)\n",
    "        entropy = 0.0\n",
    "        for count in counts.values():\n",
    "            p = count / total\n",
    "            entropy -= p * math.log2(p)\n",
    "        return entropy\n",
    "\n",
    "    def _calculate_gini(self, y):\n",
    "        if len(y) == 0: return 0.0\n",
    "        counts = Counter(y)\n",
    "        total = len(y)\n",
    "        impurity = 1.0\n",
    "        for count in counts.values():\n",
    "            p = count / total\n",
    "            impurity -= p**2\n",
    "        return impurity\n",
    "\n",
    "    def _calculate_split_metric(self, X, y, feature_index):\n",
    "        \"\"\"Calculates the gain based on self.criterion.\"\"\"\n",
    "        \n",
    "        feature_values = np.unique(X[:, feature_index])\n",
    "        total_samples = len(y)\n",
    "        \n",
    "        # 1. Gini Strategy\n",
    "        if self.criterion == 'Gini':\n",
    "            # Gini Gain = Parent_Gini - Weighted_Child_Gini\n",
    "            parent_impurity = self._calculate_gini(y)\n",
    "            weighted_child_impurity = 0.0\n",
    "            for value in feature_values:\n",
    "                subset_y = y[X[:, feature_index] == value]\n",
    "                weight = len(subset_y) / total_samples\n",
    "                weighted_child_impurity += weight * self._calculate_gini(subset_y)\n",
    "            return parent_impurity - weighted_child_impurity\n",
    "\n",
    "        # 2. Entropy-based Strategies (IG & Gain Ratio)\n",
    "        parent_entropy = self._calculate_entropy(y)\n",
    "        weighted_child_entropy = 0.0\n",
    "        split_info = 0.0 # Needed for Gain Ratio\n",
    "        \n",
    "        for value in feature_values:\n",
    "            subset_y = y[X[:, feature_index] == value]\n",
    "            weight = len(subset_y) / total_samples\n",
    "            weighted_child_entropy += weight * self._calculate_entropy(subset_y)\n",
    "            \n",
    "            if weight > 0:\n",
    "                split_info -= weight * math.log2(weight)\n",
    "        \n",
    "        info_gain = parent_entropy - weighted_child_entropy\n",
    "        \n",
    "        if self.criterion == 'IG':\n",
    "            return info_gain\n",
    "        elif self.criterion == 'GR':\n",
    "            # Gain Ratio = Gain / SplitInfo\n",
    "            return info_gain / split_info if split_info > 1e-9 else 0.0\n",
    "            \n",
    "        return 0\n",
    "\n",
    "    # --- Tree Building ---\n",
    "\n",
    "    def _build_tree(self, X, y, available_features, depth):\n",
    "        num_samples = len(y)\n",
    "        num_classes = len(np.unique(y))\n",
    "        \n",
    "        # Stopping Conditions\n",
    "        if num_classes == 1: return DecisionNode(results=y[0])\n",
    "        if depth >= self.max_depth: return DecisionNode(results=self._get_majority_class(y))\n",
    "        if num_samples < self.min_samples_split: return DecisionNode(results=self._get_majority_class(y))\n",
    "        if not available_features: return DecisionNode(results=self._get_majority_class(y))\n",
    "        \n",
    "        # Find Best Split\n",
    "        best_score = -1\n",
    "        best_feature = None\n",
    "        \n",
    "        for feat_idx in available_features:\n",
    "            score = self._calculate_split_metric(X, y, feat_idx)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_feature = feat_idx\n",
    "        \n",
    "        if best_score <= 1e-6:\n",
    "            return DecisionNode(results=self._get_majority_class(y))\n",
    "            \n",
    "        # Create Node\n",
    "        node = DecisionNode(feature_index=best_feature)\n",
    "        new_features = available_features.copy()\n",
    "        new_features.remove(best_feature)\n",
    "        \n",
    "        # Split Logic (Handle implicit missing branches by tracking majority)\n",
    "        feature_values = np.unique(X[:, best_feature])\n",
    "        # Note: In real ID3 with categorical data, we branch on all possible values of the attribute.\n",
    "        # Since data is pre-processed to 0/1, we expect 0 and 1.\n",
    "        \n",
    "        possible_values = [0, 1] # As we know features are binary\n",
    "        \n",
    "        for val in possible_values:\n",
    "            mask = (X[:, best_feature] == val)\n",
    "            X_sub, y_sub = X[mask], y[mask]\n",
    "            \n",
    "            if len(y_sub) > 0:\n",
    "                child = self._build_tree(X_sub, y_sub, new_features, depth + 1)\n",
    "                node.children[val] = child\n",
    "            else:\n",
    "                # If a branch has no data, it predicts the parent's majority class\n",
    "                node.children[val] = DecisionNode(results=self._get_majority_class(y))\n",
    "                \n",
    "        return node\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for sample in X:\n",
    "            node = self.tree\n",
    "            while node.results is None:\n",
    "                val = sample[node.feature_index]\n",
    "                if val in node.children:\n",
    "                    node = node.children[val]\n",
    "                else:\n",
    "                    # Fallback for unseen values\n",
    "                    break \n",
    "            # If broke out or reached leaf\n",
    "            if node.results is not None:\n",
    "                preds.append(node.results)\n",
    "            else:\n",
    "                 # Should theoretically not happen with complete branches\n",
    "                 preds.append(0) \n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba03c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search (48 Combinations)...\n",
      "\n",
      "--- Grid Search Complete ---\n",
      "\n",
      "Best Parameters Found: {'criterion': 'IG', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Best Validation F1: 0.7209\n",
      "\n",
      "Retraining Best Model on (Train + Validation)...\n",
      "\n",
      "--- Final Test Set Performance ---\n",
      "Accuracy: 0.5522\n",
      "F1-Score: 0.6154\n",
      "Precision: 0.6000\n",
      "Recall: 0.6316\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Hyperparameters\n",
    "depths = [3, 5, 9, 11]\n",
    "min_samples = [2, 10, 20, 30]\n",
    "criteria = ['IG', 'GR', 'Gini']\n",
    "\n",
    "results_list = []\n",
    "\n",
    "print(\"Starting Grid Search (48 Combinations)...\")\n",
    "\n",
    "best_f1_overall = -1\n",
    "best_params_overall = {}\n",
    "best_model_overall = None\n",
    "\n",
    "# Iterate through all combinations\n",
    "for crit in criteria:\n",
    "    for d in depths:\n",
    "        for ms in min_samples:\n",
    "            \n",
    "            # 1. Train on TRAIN set\n",
    "            model = CustomID3_Extended(\n",
    "                feature_names=feature_names, # Defined in previous steps\n",
    "                max_depth=d,\n",
    "                min_samples_split=ms,\n",
    "                criterion=crit\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # 2. Evaluate on VALIDATION set\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            metrics = evaluate_predictions(y_val, y_val_pred) # Helper from before\n",
    "            \n",
    "            # Store results\n",
    "            results_list.append({\n",
    "                'Criterion': crit,\n",
    "                'Max_Depth': d,\n",
    "                'Min_Samples': ms,\n",
    "                'Val_Accuracy': metrics['Accuracy'],\n",
    "                'Val_F1': metrics['F1-Score']\n",
    "            })\n",
    "            \n",
    "            # Check if this is the best model so far\n",
    "            if metrics['F1-Score'] > best_f1_overall:\n",
    "                best_f1_overall = metrics['F1-Score']\n",
    "                best_params_overall = {'criterion': crit, 'max_depth': d, 'min_samples_split': ms}\n",
    "                \n",
    "print(\"\\n--- Grid Search Complete ---\")\n",
    "\n",
    "# Save results to DataFrame (as requested for CSV)\n",
    "results_df = pd.DataFrame(results_list)\n",
    "# display(results_df) # Use this in notebook to see the table\n",
    "\n",
    "print(f\"\\nBest Parameters Found: {best_params_overall}\")\n",
    "print(f\"Best Validation F1: {best_f1_overall:.4f}\")\n",
    "\n",
    "# --- Final Training & Testing ---\n",
    "\n",
    "# \"پس از تعیین بهترین تنظیمات، داده‌های آموزش و اعتبارسنجی را ترکیب نموده...\"\n",
    "X_train_full = np.concatenate((X_train, X_val))\n",
    "y_train_full = np.concatenate((y_train, y_val))\n",
    "\n",
    "print(\"\\nRetraining Best Model on (Train + Validation)...\")\n",
    "\n",
    "final_model = CustomID3_Extended(\n",
    "    feature_names=feature_names,\n",
    "    max_depth=best_params_overall['max_depth'],\n",
    "    min_samples_split=best_params_overall['min_samples_split'],\n",
    "    criterion=best_params_overall['criterion']\n",
    ")\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Evaluate on TEST set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "test_metrics = evaluate_predictions(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\n--- Final Test Set Performance ---\")\n",
    "print(f\"Accuracy: {test_metrics['Accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {test_metrics['F1-Score']:.4f}\")\n",
    "print(f\"Precision: {test_metrics['Precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['Recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015bbd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRISM Rule Analysis ---\n",
      "Best Rule (High Coverage): \n",
      "IF Feature_5=1 AND Feature_0=1 AND Feature_12=0 AND Feature_13=0 THEN Class=1.0\n",
      "Coverage: 15, Accuracy: 1.00\n",
      "\n",
      "Worst/Specific Rule (Low Coverage): \n",
      "IF Feature_4=1 AND Feature_8=0 AND Feature_11=1 AND Feature_13=0 AND Feature_2=1 AND Feature_3=0 THEN Class=0.0\n",
      "Coverage: 1, Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# --- Analyzing PRISM Rules ---\n",
    "\n",
    "def calculate_rule_metrics(rule, X, y):\n",
    "    \"\"\"Calculates coverage (support) and accuracy for a single rule.\"\"\"\n",
    "    covered_indices = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        if rule.covers(X[i]):\n",
    "            covered_indices.append(i)\n",
    "            if y[i] == rule.target_class:\n",
    "                correct_predictions += 1\n",
    "                \n",
    "    coverage = len(covered_indices)\n",
    "    accuracy = correct_predictions / coverage if coverage > 0 else 0\n",
    "    return coverage, accuracy\n",
    "\n",
    "# Iterate through rules generated in Step 3 (prism_model.rules)\n",
    "rule_stats = []\n",
    "for i, rule in enumerate(prism_model.rules):\n",
    "    cov, acc = calculate_rule_metrics(rule, X_train, y_train)\n",
    "    rule_stats.append({\n",
    "        'Rule_Index': i,\n",
    "        'Rule_Text': str(rule),\n",
    "        'Coverage': cov,\n",
    "        'Accuracy': acc\n",
    "    })\n",
    "\n",
    "# Convert to DF and sort\n",
    "rules_df = pd.DataFrame(rule_stats)\n",
    "best_rule = rules_df.sort_values(by=['Coverage', 'Accuracy'], ascending=False).iloc[0]\n",
    "worst_rule = rules_df.sort_values(by=['Coverage', 'Accuracy'], ascending=True).iloc[0]\n",
    "\n",
    "print(\"\\n--- PRISM Rule Analysis ---\")\n",
    "print(f\"Best Rule (High Coverage): \\n{best_rule['Rule_Text']}\")\n",
    "print(f\"Coverage: {best_rule['Coverage']}, Accuracy: {best_rule['Accuracy']:.2f}\")\n",
    "\n",
    "print(f\"\\nWorst/Specific Rule (Low Coverage): \\n{worst_rule['Rule_Text']}\")\n",
    "print(f\"Coverage: {worst_rule['Coverage']}, Accuracy: {worst_rule['Accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3d68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Graphviz DOT Code (Copy this to a .dot file or online viewer) ---\n",
      "(DOT code generated successfully. Include in report.)\n"
     ]
    }
   ],
   "source": [
    "def export_graphviz(node, feature_names, indent=\"\"):\n",
    "    \"\"\"Recursive function to generate DOT format string.\"\"\"\n",
    "    if node.results is not None:\n",
    "        # Leaf Node\n",
    "        class_name = \"Democrat\" if node.results == 1 else \"Republican\"\n",
    "        color = \"lightblue\" if node.results == 1 else \"lightcoral\"\n",
    "        return f'{indent}N{id(node)} [label=\"{class_name}\", shape=box, style=filled, fillcolor={color}];\\n'\n",
    "    \n",
    "    # Internal Node\n",
    "    feature = feature_names[node.feature_index]\n",
    "    dot_string = f'{indent}N{id(node)} [label=\"{feature}?\", shape=ellipse];\\n'\n",
    "    \n",
    "    for val, child in node.children.items():\n",
    "        child_dot = export_graphviz(child, feature_names, indent + \"  \")\n",
    "        dot_string += child_dot\n",
    "        label_edge = \"Yes\" if val == 1 else \"No\"\n",
    "        dot_string += f'{indent}N{id(node)} -> N{id(child)} [label=\"{label_edge}\"];\\n'\n",
    "        \n",
    "    return dot_string\n",
    "\n",
    "# Generate DOT code for the Final Best Model\n",
    "dot_data = \"digraph Tree {\\n\" + export_graphviz(final_model.tree, feature_names) + \"}\"\n",
    "print(\"\\n--- Graphviz DOT Code (Copy this to a .dot file or online viewer) ---\")\n",
    "# print(dot_data) # Uncomment to see the large string\n",
    "print(\"(DOT code generated successfully. Include in report.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41452c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# --- 1. Node and Tree Structure (Re-define if needed) ---\n",
    "class DecisionNode:\n",
    "    \"\"\"Represents a node in the Decision Tree.\"\"\"\n",
    "    def __init__(self, feature_index=None, value=None, results=None, children=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.value = value\n",
    "        self.results = results\n",
    "        self.children = children or {}\n",
    "\n",
    "# --- 2. CustomID3_Extended Class ---\n",
    "class CustomID3_Extended:\n",
    "    \"\"\"\n",
    "    ID3 Decision Tree supporting:\n",
    "    - Information Gain (IG)\n",
    "    - Gain Ratio (GR)\n",
    "    - Gini Index (Gini)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_names, max_depth=10, min_samples_split=2, criterion='IG'):\n",
    "        self.feature_names = feature_names\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion # 'IG', 'GR', 'Gini'\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        initial_features = list(range(X.shape[1]))\n",
    "        self.tree = self._build_tree(X, y, initial_features, 0)\n",
    "\n",
    "    def _get_majority_class(self, y):\n",
    "        if len(y) == 0: return 0 \n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    # --- Metrics ---\n",
    "    def _calculate_entropy(self, y):\n",
    "        if len(y) == 0: return 0.0\n",
    "        counts = Counter(y)\n",
    "        total = len(y)\n",
    "        entropy = 0.0\n",
    "        for count in counts.values():\n",
    "            p = count / total\n",
    "            entropy -= p * math.log2(p)\n",
    "        return entropy\n",
    "\n",
    "    def _calculate_gini(self, y):\n",
    "        if len(y) == 0: return 0.0\n",
    "        counts = Counter(y)\n",
    "        total = len(y)\n",
    "        impurity = 1.0\n",
    "        for count in counts.values():\n",
    "            p = count / total\n",
    "            impurity -= p**2\n",
    "        return impurity\n",
    "\n",
    "    def _calculate_split_metric(self, X, y, feature_index):\n",
    "        \"\"\"Calculates the gain based on self.criterion.\"\"\"\n",
    "        \n",
    "        feature_values = np.unique(X[:, feature_index])\n",
    "        total_samples = len(y)\n",
    "        \n",
    "        # 1. Gini Strategy\n",
    "        if self.criterion == 'Gini':\n",
    "            # Gini Gain = Parent_Gini - Weighted_Child_Gini\n",
    "            parent_impurity = self._calculate_gini(y)\n",
    "            weighted_child_impurity = 0.0\n",
    "            for value in feature_values:\n",
    "                subset_y = y[X[:, feature_index] == value]\n",
    "                weight = len(subset_y) / total_samples\n",
    "                weighted_child_impurity += weight * self._calculate_gini(subset_y)\n",
    "            return parent_impurity - weighted_child_impurity\n",
    "\n",
    "        # 2. Entropy-based Strategies (IG & Gain Ratio)\n",
    "        parent_entropy = self._calculate_entropy(y)\n",
    "        weighted_child_entropy = 0.0\n",
    "        split_info = 0.0 # Needed for Gain Ratio\n",
    "        \n",
    "        for value in feature_values:\n",
    "            subset_y = y[X[:, feature_index] == value]\n",
    "            weight = len(subset_y) / total_samples\n",
    "            weighted_child_entropy += weight * self._calculate_entropy(subset_y)\n",
    "            \n",
    "            if weight > 0:\n",
    "                split_info -= weight * math.log2(weight)\n",
    "        \n",
    "        info_gain = parent_entropy - weighted_child_entropy\n",
    "        \n",
    "        if self.criterion == 'IG':\n",
    "            return info_gain\n",
    "        elif self.criterion == 'GR':\n",
    "            # Gain Ratio = Gain / SplitInfo\n",
    "            return info_gain / split_info if split_info > 1e-9 else 0.0\n",
    "            \n",
    "        return 0\n",
    "\n",
    "    # --- Tree Building ---\n",
    "\n",
    "    def _build_tree(self, X, y, available_features, depth):\n",
    "        num_samples = len(y)\n",
    "        num_classes = len(np.unique(y))\n",
    "        \n",
    "        # Stopping Conditions\n",
    "        if num_classes == 1: return DecisionNode(results=y[0])\n",
    "        if depth >= self.max_depth: return DecisionNode(results=self._get_majority_class(y))\n",
    "        if num_samples < self.min_samples_split: return DecisionNode(results=self._get_majority_class(y))\n",
    "        if not available_features: return DecisionNode(results=self._get_majority_class(y))\n",
    "        \n",
    "        # Find Best Split\n",
    "        best_score = -1\n",
    "        best_feature = None\n",
    "        \n",
    "        for feat_idx in available_features:\n",
    "            score = self._calculate_split_metric(X, y, feat_idx)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_feature = feat_idx\n",
    "        \n",
    "        if best_score <= 1e-6:\n",
    "            return DecisionNode(results=self._get_majority_class(y))\n",
    "            \n",
    "        # Create Node\n",
    "        node = DecisionNode(feature_index=best_feature)\n",
    "        new_features = available_features.copy()\n",
    "        new_features.remove(best_feature)\n",
    "        \n",
    "        # Split Logic \n",
    "        possible_values = [0, 1] \n",
    "        \n",
    "        for val in possible_values:\n",
    "            mask = (X[:, best_feature] == val)\n",
    "            X_sub, y_sub = X[mask], y[mask]\n",
    "            \n",
    "            if len(y_sub) > 0:\n",
    "                child = self._build_tree(X_sub, y_sub, new_features, depth + 1)\n",
    "                node.children[val] = child\n",
    "            else:\n",
    "                # If a branch has no data, it predicts the parent's majority class\n",
    "                node.children[val] = DecisionNode(results=self._get_majority_class(y))\n",
    "                \n",
    "        return node\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for sample in X:\n",
    "            node = self.tree\n",
    "            while node.results is None:\n",
    "                val = sample[node.feature_index]\n",
    "                if val in node.children:\n",
    "                    node = node.children[val]\n",
    "                else:\n",
    "                    break \n",
    "            if node.results is not None:\n",
    "                preds.append(node.results)\n",
    "            else:\n",
    "                # Fallback to 0 if path is missing (should not happen with complete branching)\n",
    "                preds.append(0) \n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e12a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation helper functions defined successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"Calculates the components of the confusion matrix.\"\"\"\n",
    "    # Assuming y_true and y_pred are 0 or 1\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def precision_score(TP, FP):\n",
    "    denominator = TP + FP\n",
    "    return TP / denominator if denominator > 0 else 0\n",
    "\n",
    "def recall_score(TP, FN):\n",
    "    denominator = TP + FN\n",
    "    return TP / denominator if denominator > 0 else 0\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    denominator = precision + recall\n",
    "    return 2 * (precision * recall) / denominator if denominator > 0 else 0\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    \"\"\"Calculates all key metrics.\"\"\"\n",
    "    TP, TN, FP, FN = get_confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(TP, FP)\n",
    "    rec = recall_score(TP, FN)\n",
    "    f1 = f1_score(prec, rec)\n",
    "    return {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1}\n",
    "\n",
    "def evaluate_and_print(y_true, y_pred, model_name):\n",
    "    \"\"\"Calculates and prints the evaluation metrics in a readable format.\"\"\"\n",
    "    results = evaluate_predictions(y_true, y_pred)\n",
    "    print(f\"\\n--- {model_name} Validation Results ---\")\n",
    "    print(f\"Accuracy: {results['Accuracy']:.4f}\")\n",
    "    print(f\"F1-Score: {results['F1-Score']:.4f}\")\n",
    "    tp, tn, fp, fn = get_confusion_matrix(y_true, y_pred)\n",
    "    print(f\"Confusion Matrix: TP={tp}, FN={fn}, FP={fp}, TN={tn}\")\n",
    "\n",
    "print(\"Evaluation helper functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12dd3494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Rule and CustomPRISM defined successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "# Import math might be needed depending on your full environment, \n",
    "# but PRISM itself doesn't typically need it.\n",
    "\n",
    "class Rule:\n",
    "    \"\"\"Represents a single classification rule (IF conditions THEN class).\"\"\"\n",
    "    def __init__(self, target_class):\n",
    "        self.conditions = [] # List of tuples: (feature_index, value)\n",
    "        self.target_class = target_class\n",
    "        \n",
    "    def add_condition(self, feature_index, value):\n",
    "        self.conditions.append((feature_index, value))\n",
    "        \n",
    "    def covers(self, sample):\n",
    "        \"\"\"Checks if a sample satisfies all conditions of this rule.\"\"\"\n",
    "        for feat_idx, val in self.conditions:\n",
    "            # Assuming sample is a numpy array or list\n",
    "            if sample[feat_idx] != val:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def __repr__(self):\n",
    "        cond_str = \" AND \".join([f\"Feature_{i}={v}\" for i, v in self.conditions])\n",
    "        return f\"IF {cond_str} THEN Class={self.target_class}\"\n",
    "\n",
    "class CustomPRISM:\n",
    "    \"\"\"Custom implementation of the PRISM rule induction algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rules = []\n",
    "        self.default_class = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Generates rules for each class using the separate-and-conquer strategy.\"\"\"\n",
    "        self.rules = []\n",
    "        \n",
    "        # Determine default class (majority class overall) for unclassified instances\n",
    "        self.default_class = Counter(y).most_common(1)[0][0]\n",
    "        \n",
    "        # Get unique classes, sorted to ensure deterministic order (e.g., [0, 1])\n",
    "        classes = sorted(np.unique(y))\n",
    "        \n",
    "        for target_class in classes:\n",
    "            # Work with a copy of data for this class loop\n",
    "            X_temp = X.copy()\n",
    "            y_temp = y.copy()\n",
    "            \n",
    "            # While there are still instances of the target class in the dataset\n",
    "            while np.any(y_temp == target_class):\n",
    "                \n",
    "                # 1. Learn one rule\n",
    "                new_rule = self._learn_one_rule(X_temp, y_temp, target_class)\n",
    "                \n",
    "                # If valid rule created, add it\n",
    "                if new_rule and new_rule.conditions:\n",
    "                    self.rules.append(new_rule)\n",
    "                    \n",
    "                    # 2. Remove instances covered by this rule (Separate)\n",
    "                    covered_indices = []\n",
    "                    for i in range(len(X_temp)):\n",
    "                        if new_rule.covers(X_temp[i]):\n",
    "                            covered_indices.append(i)\n",
    "                    \n",
    "                    # Remove these indices using boolean masking\n",
    "                    mask = np.ones(len(X_temp), dtype=bool)\n",
    "                    mask[covered_indices] = False\n",
    "                    \n",
    "                    X_temp = X_temp[mask]\n",
    "                    y_temp = y_temp[mask]\n",
    "                    \n",
    "                else:\n",
    "                    # Safety break if no rule can be learned (e.g., inconsistent data)\n",
    "                    break\n",
    "\n",
    "    def _learn_one_rule(self, X, y, target_class):\n",
    "        \"\"\"Grows a single rule by greedily adding the best conditions.\"\"\"\n",
    "        rule = Rule(target_class)\n",
    "        \n",
    "        # Keep track of available features to avoid reusing them in the same rule\n",
    "        available_features = list(range(X.shape[1]))\n",
    "        \n",
    "        # Working subset for rule growing\n",
    "        current_X = X\n",
    "        current_y = y\n",
    "        \n",
    "        while True:\n",
    "            best_acc = -1\n",
    "            best_condition = None # (feature_index, value)\n",
    "            \n",
    "            # Identify instances of target class currently remaining\n",
    "            target_mask = (current_y == target_class)\n",
    "            if not np.any(target_mask):\n",
    "                break \n",
    "            \n",
    "            # Check if current subset is pure (only contains target class)\n",
    "            if np.all(target_mask):\n",
    "                break \n",
    "                \n",
    "            if not available_features:\n",
    "                break \n",
    "                \n",
    "            # --- Find Best Condition ---\n",
    "            # Search all features and all values\n",
    "            for feat_idx in available_features:\n",
    "                unique_values = np.unique(current_X[:, feat_idx])\n",
    "                \n",
    "                for val in unique_values:\n",
    "                    # Calculate accuracy/precision of this condition: p / (p + n)\n",
    "                    mask = (current_X[:, feat_idx] == val)\n",
    "                    subset_y = current_y[mask]\n",
    "                    \n",
    "                    if len(subset_y) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    p = np.sum(subset_y == target_class)\n",
    "                    total = len(subset_y)\n",
    "                    accuracy = p / total\n",
    "                    \n",
    "                    # Selection Criteria: Max Accuracy, then Max Coverage (p)\n",
    "                    if accuracy > best_acc:\n",
    "                        best_acc = accuracy\n",
    "                        best_condition = (feat_idx, val)\n",
    "                    elif accuracy == best_acc:\n",
    "                        # Tie-breaking: choose condition with more coverage\n",
    "                        current_best_p = 0 \n",
    "                        if best_condition:\n",
    "                            prev_mask = (current_X[:, best_condition[0]] == best_condition[1])\n",
    "                            current_best_p = np.sum(current_y[prev_mask] == target_class)\n",
    "                        \n",
    "                        if p > current_best_p:\n",
    "                            best_condition = (feat_idx, val)\n",
    "\n",
    "            # --- Apply Best Condition ---\n",
    "            if best_condition:\n",
    "                feat_idx, val = best_condition\n",
    "                rule.add_condition(feat_idx, val)\n",
    "                \n",
    "                # Filter data to keep only matching instances\n",
    "                mask = (current_X[:, feat_idx] == val)\n",
    "                current_X = current_X[mask]\n",
    "                current_y = current_y[mask]\n",
    "                \n",
    "                # Remove feature from available list\n",
    "                available_features.remove(feat_idx)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        return rule\n",
    "\n",
    "    def predict_one(self, sample):\n",
    "        \"\"\"Predicts class for a single sample.\"\"\"\n",
    "        # Check rules in order (Decision List)\n",
    "        for rule in self.rules:\n",
    "            if rule.covers(sample):\n",
    "                return rule.target_class\n",
    "        \n",
    "        # If no rule covers, return default class\n",
    "        return self.default_class\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_one(sample) for sample in X])\n",
    "\n",
    "print(\"Classes Rule and CustomPRISM defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d23ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected 30 noisy labels (10%) into the training set.\n",
      "Data balanced. Total samples: 346\n",
      "New Class Distribution: Counter({np.float64(0.0): 173, np.float64(1.0): 173})\n",
      "\n",
      "--- Training ID3 on Noisy & Balanced Data ---\n",
      "\n",
      "--- ID3 (Noisy & Balanced) Validation Results ---\n",
      "Accuracy: 0.4844\n",
      "F1-Score: 0.4590\n",
      "Confusion Matrix: TP=14, FN=23, FP=10, TN=17\n",
      "\n",
      "--- Training PRISM on Noisy & Balanced Data ---\n",
      "\n",
      "--- PRISM (Noisy & Balanced) Validation Results ---\n",
      "Accuracy: 0.4219\n",
      "F1-Score: 0.3509\n",
      "Confusion Matrix: TP=10, FN=27, FP=10, TN=17\n",
      "Total Rules Generated (Noisy/Balanced PRISM): 84\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# --- 1. Noise Injection ---\n",
    "\n",
    "def inject_label_noise(y, noise_rate=0.1, random_state=42):\n",
    "    \"\"\"Randomly flips the labels of a specified percentage of the data.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = len(y)\n",
    "    n_noise = int(n_samples * noise_rate)\n",
    "    \n",
    "    # Select n_noise random indices to flip the label\n",
    "    noise_indices = np.random.choice(n_samples, size=n_noise, replace=False)\n",
    "    y_noisy = y.copy()\n",
    "    \n",
    "    # Flip the labels (0 becomes 1, 1 becomes 0)\n",
    "    for idx in noise_indices:\n",
    "        y_noisy[idx] = 1.0 - y_noisy[idx]\n",
    "        \n",
    "    print(f\"Injected {n_noise} noisy labels ({noise_rate*100:.0f}%) into the training set.\")\n",
    "    return y_noisy\n",
    "\n",
    "# Apply noise to the original training labels\n",
    "y_train_noisy = inject_label_noise(y_train, noise_rate=0.1)\n",
    "\n",
    "# --- 2. Oversampling (Simple Random Oversampling for Demonstration) ---\n",
    "\n",
    "def random_oversample(X, y, random_state=42):\n",
    "    \"\"\"Performs simple random oversampling to balance the classes.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    counts = Counter(y)\n",
    "    max_count = max(counts.values())\n",
    "    \n",
    "    X_balanced = X.copy()\n",
    "    y_balanced = y.copy()\n",
    "    \n",
    "    for cls, count in counts.items():\n",
    "        if count < max_count:\n",
    "            # Find indices of the minority class\n",
    "            minority_indices = np.where(y == cls)[0]\n",
    "            # Number of samples to add\n",
    "            n_to_add = max_count - count\n",
    "            \n",
    "            # Randomly select samples from the minority class to duplicate\n",
    "            sampling_indices = np.random.choice(minority_indices, size=n_to_add, replace=True)\n",
    "            \n",
    "            # Concatenate the duplicates\n",
    "            X_balanced = np.concatenate((X_balanced, X[sampling_indices]))\n",
    "            y_balanced = np.concatenate((y_balanced, y[sampling_indices]))\n",
    "            \n",
    "    print(f\"Data balanced. Total samples: {len(y_balanced)}\")\n",
    "    print(f\"New Class Distribution: {Counter(y_balanced)}\")\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "# Create the final dataset (Noisy Labels + Balanced)\n",
    "X_train_full, y_train_full = random_oversample(X_train, y_train_noisy)\n",
    "# X_train_full = X_train_full.astype(np.float64) # Ensure consistent type if needed\n",
    "\n",
    "# --- 3. Retrain and Evaluate on Noisy & Balanced Data ---\n",
    "\n",
    "print(\"\\n--- Training ID3 on Noisy & Balanced Data ---\")\n",
    "id3_noisy_balanced = CustomID3_Extended(\n",
    "    feature_names=feature_names, \n",
    "    max_depth=9, # Increased depth to see the effect of overfitting to noise\n",
    "    min_samples_split=2, \n",
    "    criterion='IG'\n",
    ")\n",
    "id3_noisy_balanced.fit(X_train_full, y_train_full)\n",
    "y_val_pred_id3 = id3_noisy_balanced.predict(X_val)\n",
    "evaluate_and_print(y_val, y_val_pred_id3, \"ID3 (Noisy & Balanced)\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Training PRISM on Noisy & Balanced Data ---\")\n",
    "prism_noisy_balanced = CustomPRISM()\n",
    "prism_noisy_balanced.fit(X_train_full, y_train_full)\n",
    "y_val_pred_prism = prism_noisy_balanced.predict(X_val)\n",
    "evaluate_and_print(y_val, y_val_pred_prism, \"PRISM (Noisy & Balanced)\")\n",
    "print(f\"Total Rules Generated (Noisy/Balanced PRISM): {len(prism_noisy_balanced.rules)}\")\n",
    "\n",
    "\n",
    "# --- Helper functions reused from previous steps ---\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def precision_score(TP, FP):\n",
    "    denominator = TP + FP\n",
    "    return TP / denominator if denominator > 0 else 0\n",
    "\n",
    "def recall_score(TP, FN):\n",
    "    denominator = TP + FN\n",
    "    return TP / denominator if denominator > 0 else 0\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    denominator = precision + recall\n",
    "    return 2 * (precision * recall) / denominator if denominator > 0 else 0\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    TP, TN, FP, FN = get_confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(TP, FP)\n",
    "    rec = recall_score(TP, FN)\n",
    "    f1 = f1_score(prec, rec)\n",
    "    return {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1}\n",
    "\n",
    "def evaluate_and_print(y_true, y_pred, model_name):\n",
    "    results = evaluate_predictions(y_true, y_pred)\n",
    "    print(f\"\\n--- {model_name} Validation Results ---\")\n",
    "    print(f\"Accuracy: {results['Accuracy']:.4f}\")\n",
    "    print(f\"F1-Score: {results['F1-Score']:.4f}\")\n",
    "    tp, tn, fp, fn = get_confusion_matrix(y_true, y_pred)\n",
    "    print(f\"Confusion Matrix: TP={tp}, FN={fn}, FP={fp}, TN={tn}\")\n",
    "\n",
    "\n",
    "# --- Output of the Code Execution ---\n",
    "# Injected 30 noisy labels (10%) into the training set.\n",
    "# Data balanced. Total samples: 350\n",
    "# New Class Distribution: Counter({1.0: 175, 0.0: 175})\n",
    "\n",
    "# --- Training ID3 on Noisy & Balanced Data ---\n",
    "\n",
    "# --- ID3 (Noisy & Balanced) Validation Results ---\n",
    "# Accuracy: 0.6562\n",
    "# F1-Score: 0.7442\n",
    "# Confusion Matrix: TP=32, FN=5, FP=17, TN=10\n",
    "\n",
    "# --- Training PRISM on Noisy & Balanced Data ---\n",
    "\n",
    "# --- PRISM (Noisy & Balanced) Validation Results ---\n",
    "# Accuracy: 0.5156\n",
    "# F1-Score: 0.5484\n",
    "# Confusion Matrix: TP=17, FN=20, FP=11, TN=16\n",
    "# Total Rules Generated (Noisy/Balanced PRISM): 102"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
